{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "together-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from mpl_toolkits import mplot3d\n",
    "from numpy import set_printoptions\n",
    "from numpy import absolute\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import get_test_data\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loose-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "prosody_data = pd.read_csv('prosodic_features_M.csv ')\n",
    "turker_score = pd.read_csv('Turker_Score_M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exempt-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "dA = pd.read_csv('prosodic_features_M2.csv ')\n",
    "yRH = prosody_data['RecommendHiring']\n",
    "yF = prosody_data['Friendly']\n",
    "ySA = turker_score['StructuredAnswers']\n",
    "yNS = prosody_data['NotStressed']\n",
    "cRH = prosody_data['Hired']\n",
    "cF = prosody_data['Friendly_c']\n",
    "cSA = prosody_data['StructuredAnswers_c']\n",
    "yNS = turker_score['NotStressed']\n",
    "\n",
    "yCLG= turker_score['Colleague']\n",
    "yEXTD = turker_score['Excited']\n",
    "ySPKR = turker_score['SpeakingRate']\n",
    "yNF = turker_score['NoFillers']\n",
    "yPSD = turker_score['Paused']\n",
    "yENGT =  turker_score['EngagingTone']\n",
    "yCalm =  turker_score['Calm']\n",
    "yNAWKD =turker_score['NotAwkward']\n",
    "yFOC = turker_score['Focused']\n",
    "yAUT = turker_score['Authentic']\n",
    "\n",
    "MAUT = turker_score['Authentic_M']\n",
    "MFOC = turker_score['Focused_M']\n",
    "MNAWKD =turker_score['NotAwkward_M']\n",
    "MNS = turker_score['NotStressed_M']\n",
    "MCalm =  turker_score['Calm_M']\n",
    "MENGT =  turker_score['EngagingTone_M']\n",
    "MPSD = turker_score['Paused_M']\n",
    "MNF =turker_score['NoFillers_M']\n",
    "MSPKR = turker_score['SpeakingRate_M']\n",
    "MEXTD = turker_score['Excited_M']\n",
    "MRH = prosody_data['Hired_M']\n",
    "MF= prosody_data['Friendly_M']\n",
    "MENG = turker_score['Engaged_M']\n",
    "MCLG =turker_score['Colleague_M'] \n",
    "MSA = turker_score['StructuredAnswers_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certified-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = {}\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    #ranks = map(lambda x: round(x, 5), ranks)\n",
    "    return dict(zip(names, ranks ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stuck-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_kbest(prosody_data_y):\n",
    "    array =  prosody_data.values\n",
    "\n",
    "    X = prosody_data_X\n",
    "    Y = prosody_data_y\n",
    "    # feature extraction\n",
    "    kbest_test = SelectKBest(score_func=f_classif, k=4)\n",
    "    fit = kbest_test.fit(X, Y)\n",
    "    # summarize scores\n",
    "    set_printoptions(precision=3)\n",
    "    #print(fit.scores_)\n",
    "    features = fit.transform(X)\n",
    "    # summarize selected features\n",
    "    #print(features[0:5,:])\n",
    "\n",
    "    ranks[\"kbest\"] = rank_to_dict(np.abs(fit.scores_), prosody_data_X)\n",
    "    rankDict = {}\n",
    "    rankDict = ranks[\"kbest\"]\n",
    "    return rankDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-compensation",
   "metadata": {},
   "source": [
    "# Making arrays of Top 10 20 30 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "healthy-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(rankDict):\n",
    "    selectedFeatures = []\n",
    "\n",
    "    selectedFeatures = dict(sorted(rankDict.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "\n",
    "    selectedFeatures_10 = []\n",
    "    i=0\n",
    "    for key in selectedFeatures.keys():\n",
    "        if(i<10):\n",
    "            selectedFeatures_10.append(key)\n",
    "            i+=1\n",
    "\n",
    "    selectedFeatures_20 = []\n",
    "    i=0\n",
    "    for key in selectedFeatures.keys():\n",
    "        if(i<20):\n",
    "            selectedFeatures_20.append(key)\n",
    "            i+=1\n",
    "\n",
    "    selectedFeatures_30 = []\n",
    "    i=0\n",
    "    for key in selectedFeatures.keys():\n",
    "        if(i<30):\n",
    "            selectedFeatures_30.append(key)\n",
    "            i+=1\n",
    "    return selectedFeatures_10,selectedFeatures_20,selectedFeatures_30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focal-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "prosody_data_X = prosody_data.drop(['participant&question','Hired','RecommendHiring','Friendly','Friendly_M','Friendly_c','StructuredAnswers','StructuredAnswers_c','NotStressed','NotStressed_c','Colleague','Hired_M'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-chinese",
   "metadata": {},
   "source": [
    "# Feature selection for using KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "olive-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores of Features\n"
     ]
    }
   ],
   "source": [
    "#feature ranks for \n",
    "prosody_data_y = yAUT\n",
    "X_train, X_test, y_train, y_test = train_test_split(prosody_data_X, prosody_data_y, test_size=0.20, random_state=10)\n",
    "selectedFeatures_Kbest=select_feature_kbest(yAUT)\n",
    "print(\"\\nScores of Features\")\n",
    "#selectedFeatures_RecommendHiring_Kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elegant-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeatures_kbest_10,selectedFeatures_kbest_20,selectedFeatures_kbest_30= select_features(selectedFeatures_Kbest)\n",
    "\n",
    "#print(\"Top 10 Selected Features Using kbest:\",selectedFeatures_kbest_10)\n",
    "\n",
    "#print(\"\\n\\n\\nTop 20 Selected Features Using kbest:\",selectedFeatures_kbest_20)\n",
    "\n",
    "#print(\"\\n\\n\\nTop 30 Selected Features Using kbest:\",selectedFeatures_kbest_30 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-cover",
   "metadata": {},
   "source": [
    "# Applying Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "logical-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exceptional-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_NN_Moadel(no_of_inNeurons,no_of_hiddenLayerNeurons,no_of_epochs,selectedFeatures_No,d_Var):\n",
    "    scaler = MinMaxScaler()\n",
    "    X=prosody_data[selectedFeatures_No].values\n",
    "    X =  scaler.fit_transform(X)\n",
    "    Y=d_Var\n",
    "    #encode class values as integers\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    encoded_Y = encoder.transform(Y)\n",
    "    #print(X)\n",
    "    \n",
    "    #print(encoded_Y)\n",
    "    \n",
    "    def baseline_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(no_of_hiddenLayerNeurons, input_dim=no_of_inNeurons, activation='relu'))\n",
    "        model.add(Dense(no_of_hiddenLayerNeurons, input_dim=no_of_inNeurons, activation='relu'))\n",
    "        model.add(Dense(no_of_hiddenLayerNeurons, input_dim=no_of_inNeurons, activation='relu'))\n",
    "        model.add(Dense(no_of_hiddenLayerNeurons, input_dim=no_of_inNeurons, activation='relu'))\n",
    "        model.add(Dense(no_of_hiddenLayerNeurons, input_dim=no_of_inNeurons, activation='relu'))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    estimator = KerasClassifier(build_fn=baseline_model, epochs=no_of_epochs, batch_size=5, verbose=0)\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "    print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-skating",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "cvscores_NN_10_kbest= [] \n",
    "#(model_NN_10_kbest,cvscores_NN_10_kbest,FP_Rate_NN_10_kbest,TP_Rate_NN_10_kbest,auc_NN_10_kbest_) = \n",
    "apply_NN_Moadel(10,18,200,selectedFeatures_kbest_10,MF,TRH1,TRH2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-scanning",
   "metadata": {},
   "source": [
    "cvscores_NN_20_kbest= [] \n",
    "#(model_NN_10_kbest,cvscores_NN_10_kbest,FP_Rate_NN_10_kbest,TP_Rate_NN_10_kbest,auc_NN_10_kbest_) = \n",
    "apply_NN_Moadel(20,18,200,selectedFeatures_kbest_20,MF,TRH1,TRH2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-singles",
   "metadata": {},
   "source": [
    "cvscores_NN_20_kbest= []  \n",
    "#(model_NN_10_kbest,cvscores_NN_10_kbest,FP_Rate_NN_10_kbest,TP_Rate_NN_10_kbest,auc_NN_10_kbest_) = \n",
    "apply_NN_Moadel(20,18,200,selectedFeatures_kbest_20,MENG,TRH1,TRH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distinguished-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 71.76% (4.30%)\n"
     ]
    }
   ],
   "source": [
    "cvscores_NN_20_kbest= []  \n",
    "#(model_NN_10_kbest,cvscores_NN_10_kbest,FP_Rate_NN_10_kbest,TP_Rate_NN_10_kbest,auc_NN_10_kbest_) = \n",
    "apply_NN_Moadel(20,18,200,selectedFeatures_kbest_20,MAUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "arabic-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_Model(model,model_name,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    clf = model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)            \n",
    "    \n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    # fit a model\n",
    "    model.fit(X_train,y_train)\n",
    "    # predict probabilities\n",
    "    m_probs = model.predict_proba(X_test)\n",
    "        \n",
    "    # keep probabilities for the positive outcome only\n",
    "    m_probs = m_probs[:, 1]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    m_auc = roc_auc_score(y_test, m_probs)\n",
    "    # summarize scores\n",
    "    # print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    # print('Logistic: ROC AUC=%.3f' % (m_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    m_fpr, m_tpr, _ = roc_curve(y_test, m_probs)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(m_fpr, m_tpr, marker='.', label=model_name)   \n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(confusion_matrix(y_test,pred))\n",
    "    print(classification_report(y_test,pred,zero_division=0))\n",
    "    \n",
    "    print('MSE',metrics.mean_squared_error(y_test,pred))\n",
    "    \n",
    "    if(model == svc_model):\n",
    "      m_Cross = cross_val_score(model,X20,y20,cv=10)\n",
    "    elif(model == knn):\n",
    "      m_Cross = cross_val_score(model,X20,y20,cv=10)\n",
    "    elif(model == rfc):\n",
    "      m_Cross = cross_val_score(model,X20,y20,cv=10)\n",
    "    print(\"Mean : \",m_Cross)\n",
    "    print(\"CV Score  %.2f%% (+/- %.2f%%)\" % (np.mean(m_Cross), np.std(m_Cross)))\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize = (10,6))\n",
    "    sns.heatmap(confusion_matrix(y_test, pred), annot = True,fmt='d')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return (m_fpr, m_tpr,m_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hispanic-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "X20=prosody_data[selectedFeatures_kbest_20]\n",
    "y20=MRH\n",
    "X20_train, X20_test, y20_train, y20_test = train_test_split(X20, y20, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "static-damage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.779, 0.809, 0.647, 0.838, 0.809, 0.75 , 0.809, 0.75 , 0.809,\n",
       "       0.853])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=600)\n",
    "#(rfc_fpr, rfc_tpr, rfc_auc)=Apply_Model(rfc,\"RFC\",X20_train, X20_test, y20_train, y20_test)\n",
    "\n",
    "cross_val_score(rfc, X20, y20,cv=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
